{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ijson # $pip install ijson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import zenodotus as z\n",
    "import noun_phrase_extractor as npe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando dados de origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Leitura do DataFrame\n",
    "datapath = \"raw.json\"\n",
    "\n",
    "sentences = []\n",
    "\n",
    "with open(datapath, 'r') as f:\n",
    "    objects = ijson.items(f, 'topics.item.subject') #Pulo do gato: item:são os elementos de uma lista\n",
    "    sentences = list(objects)\n",
    "\n",
    "    \n",
    "with open(datapath, 'r') as f:\n",
    "    objects2 = ijson.items(f, 'topics.item.question')\n",
    "    sentences.extend(list(objects2))\n",
    "\n",
    "    \n",
    "source  = pd.DataFrame({'sentence':sentences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list of hispanic actors?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LiST OF ACTORS AND ACTRESSES?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are a and b list actors?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List of famous black actors?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence\n",
       "0  Bad rap actors good rap actors list?\n",
       "1              list of hispanic actors?\n",
       "2         LiST OF ACTORS AND ACTRESSES?\n",
       "3          Who are a and b list actors?\n",
       "4          List of famous black actors?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#existem dados faltantes?\n",
    "source[source['sentence']==''].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removendo...\n",
    "source = source[source['sentence']!='']\n",
    "#depois da remoção\n",
    "source[source['sentence']==''].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenização\n",
    "source['tokenized'] = source.apply(lambda row: word_tokenize(row['sentence'].lower()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tagged</th>\n",
       "      <th>noun-phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "      <td>[bad, rap, actors, good, rap, actors, list, ?]</td>\n",
       "      <td>[(Bad, NNP), (rap, NN), (actor, NNS), (good, J...</td>\n",
       "      <td>[[bad, rap, actor, good, rap, actor, list]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list of hispanic actors?</td>\n",
       "      <td>[list, of, hispanic, actors, ?]</td>\n",
       "      <td>[(list, NN), (of, IN), (hispanic, JJ), (actor,...</td>\n",
       "      <td>[[list], [hispanic, actor]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LiST OF ACTORS AND ACTRESSES?</td>\n",
       "      <td>[list, of, actors, and, actresses, ?]</td>\n",
       "      <td>[(LiST, NN), (OF, IN), (ACTORS, NNP), (AND, NN...</td>\n",
       "      <td>[[list,  act, ors and actresses?]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are a and b list actors?</td>\n",
       "      <td>[who, are, a, and, b, list, actors, ?]</td>\n",
       "      <td>[(Who, WP), (are, VBP), (a, DT), (and, CC), (b...</td>\n",
       "      <td>[[list, actor]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List of famous black actors?</td>\n",
       "      <td>[list, of, famous, black, actors, ?]</td>\n",
       "      <td>[(List, NN), (of, IN), (famous, JJ), (black, J...</td>\n",
       "      <td>[[list], [famous, black, actor]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence  \\\n",
       "0  Bad rap actors good rap actors list?   \n",
       "1              list of hispanic actors?   \n",
       "2         LiST OF ACTORS AND ACTRESSES?   \n",
       "3          Who are a and b list actors?   \n",
       "4          List of famous black actors?   \n",
       "\n",
       "                                        tokenized  \\\n",
       "0  [bad, rap, actors, good, rap, actors, list, ?]   \n",
       "1                 [list, of, hispanic, actors, ?]   \n",
       "2           [list, of, actors, and, actresses, ?]   \n",
       "3          [who, are, a, and, b, list, actors, ?]   \n",
       "4            [list, of, famous, black, actors, ?]   \n",
       "\n",
       "                                              tagged  \\\n",
       "0  [(Bad, NNP), (rap, NN), (actor, NNS), (good, J...   \n",
       "1  [(list, NN), (of, IN), (hispanic, JJ), (actor,...   \n",
       "2  [(LiST, NN), (OF, IN), (ACTORS, NNP), (AND, NN...   \n",
       "3  [(Who, WP), (are, VBP), (a, DT), (and, CC), (b...   \n",
       "4  [(List, NN), (of, IN), (famous, JJ), (black, J...   \n",
       "\n",
       "                                  noun-phrases  \n",
       "0  [[bad, rap, actor, good, rap, actor, list]]  \n",
       "1                  [[list], [hispanic, actor]]  \n",
       "2           [[list,  act, ors and actresses?]]  \n",
       "3                              [[list, actor]]  \n",
       "4             [[list], [famous, black, actor]]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source['tagged'] = source.apply(lambda row: pos_tag(row['tokenized']),axis=1)\n",
    "\n",
    "#Lematiza somente a o token, mantendo a tag original do token antes da lematização (actors, NNS) -> (actor, NNS)\n",
    "Lemmatizer = WordNetLemmatizer()\n",
    "for i in source['tagged'].index:\n",
    "    lista_aux = []\n",
    "    for tupla in source['tagged'][i]:\n",
    "        lista_aux.append( (Lemmatizer.lemmatize(tupla[0]), tupla[1]) )\n",
    "    source['tagged'][i] = lista_aux\n",
    "    \n",
    "source['noun-phrases'] = source.apply(lambda row: npe.extract(row['sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tagged</th>\n",
       "      <th>noun-phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "      <td>[bad, rap, actors, good, rap, actors, list, ?]</td>\n",
       "      <td>[(bad, JJ), (rap, NN), (actor, NNS), (good, JJ...</td>\n",
       "      <td>[[bad, rap, actor, good, rap, actor, list]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list of hispanic actors?</td>\n",
       "      <td>[list, of, hispanic, actors, ?]</td>\n",
       "      <td>[(list, NN), (of, IN), (hispanic, JJ), (actor,...</td>\n",
       "      <td>[[list], [hispanic, actor]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LiST OF ACTORS AND ACTRESSES?</td>\n",
       "      <td>[list, of, actors, and, actresses, ?]</td>\n",
       "      <td>[(list, NN), (of, IN), (actor, NNS), (and, CC)...</td>\n",
       "      <td>[[list,  act, ors and actresses?]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are a and b list actors?</td>\n",
       "      <td>[who, are, a, and, b, list, actors, ?]</td>\n",
       "      <td>[(who, WP), (are, VBP), (a, DT), (and, CC), (b...</td>\n",
       "      <td>[[list, actor]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List of famous black actors?</td>\n",
       "      <td>[list, of, famous, black, actors, ?]</td>\n",
       "      <td>[(list, NN), (of, IN), (famous, JJ), (black, J...</td>\n",
       "      <td>[[list], [famous, black, actor]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence  \\\n",
       "0  Bad rap actors good rap actors list?   \n",
       "1              list of hispanic actors?   \n",
       "2         LiST OF ACTORS AND ACTRESSES?   \n",
       "3          Who are a and b list actors?   \n",
       "4          List of famous black actors?   \n",
       "\n",
       "                                        tokenized  \\\n",
       "0  [bad, rap, actors, good, rap, actors, list, ?]   \n",
       "1                 [list, of, hispanic, actors, ?]   \n",
       "2           [list, of, actors, and, actresses, ?]   \n",
       "3          [who, are, a, and, b, list, actors, ?]   \n",
       "4            [list, of, famous, black, actors, ?]   \n",
       "\n",
       "                                              tagged  \\\n",
       "0  [(bad, JJ), (rap, NN), (actor, NNS), (good, JJ...   \n",
       "1  [(list, NN), (of, IN), (hispanic, JJ), (actor,...   \n",
       "2  [(list, NN), (of, IN), (actor, NNS), (and, CC)...   \n",
       "3  [(who, WP), (are, VBP), (a, DT), (and, CC), (b...   \n",
       "4  [(list, NN), (of, IN), (famous, JJ), (black, J...   \n",
       "\n",
       "                                  noun-phrases  \n",
       "0  [[bad, rap, actor, good, rap, actor, list]]  \n",
       "1                  [[list], [hispanic, actor]]  \n",
       "2           [[list,  act, ors and actresses?]]  \n",
       "3                              [[list, actor]]  \n",
       "4             [[list], [famous, black, actor]]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for i,row in source.iterrows():\n",
    "    for phrase in row['noun-phrases']:\n",
    "        for word in phrase:\n",
    "            words.append(word)\n",
    "nellkb = pd.DataFrame({'word':words})\n",
    "\n",
    "#Removendo repetições\n",
    "nellkb = nellkb.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nellkb['is_category'] = nellkb.apply(lambda row: z.isCategory(row['word']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = nellkb[nellkb['is_category'] == 'yes']['word'].tolist()\n",
    "nellkb['is_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "for irow, row in source.iterrows():\n",
    "    print(source['sentence'][irow])\n",
    "    #Gerando um dataframe provisório para busca nos dados\n",
    "    tagged_data_frame = pd.DataFrame(source['tagged'][irow],columns=['word','tag'])\n",
    "    \n",
    "    #transformando em minúsculas\n",
    "    tagged_data_frame['word'] = tagged_data_frame.apply(lambda row: row['word'].lower(),axis=1)\n",
    "    \n",
    "    #print(tagged_data_frame.head())\n",
    "       \n",
    "    for iphrase, phrase in enumerate(row['noun-phrases']):\n",
    "        for iword, word in enumerate(phrase):\n",
    "            print(word in tagged_data_frame['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = {'sentence':[],'word':[],'word_tag':[],'word_is_category':[]\n",
    "#                          ,'nell_category':[],'nell_category_tag':[],'distance_from_category':[]\n",
    "#                         ,'number_of_occurrences':[],'is_category_candidate':[]}\n",
    "dataset = pd.DataFrame()\n",
    "for irow, row in source.iterrows():\n",
    "    for iphrase, phrase in enumerate(row['noun-phrases']):\n",
    "        print(irow,iphrase,phrase)\n",
    "        is_category = []\n",
    "        #Buscando categorias na base da NELL e Gerando o Dataframe\n",
    "        for word in phrase:\n",
    "            cat = z.getCategory(word)\n",
    "            #Verifica se a palavra é uma categoria da NELL\n",
    "            if(cat['category_name'] is not None): \n",
    "                is_category.append('yes')\n",
    "            else:\n",
    "                is_category.append('no')\n",
    "        df = pd.DataFrame({'word':phrase, 'is_category':is_category})\n",
    "        words_list = []\n",
    "        categories = []\n",
    "        for category in df[df['is_category'] == 'yes']['word'].items():\n",
    "            for word in df[df['word'] != category[1]]['word'].items():\n",
    "                words_list.append(word[1])\n",
    "                categories.append(category[1])\n",
    "        dfr = pd.DataFrame({'word':words_list, 'category':categories})\n",
    "        dataset = pd.concat([dataset,dfr])\n",
    "        print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
