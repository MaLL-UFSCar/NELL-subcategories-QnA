{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanto bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ijson # $pip install ijson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import zenodotus as z\n",
    "import noun_phrase_extractor as npe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando dados de origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Leitura do DataFrame\n",
    "datapath = \"raw.json\"\n",
    "\n",
    "sentences = []\n",
    "\n",
    "#Subjects\n",
    "with open(datapath, 'r') as f:\n",
    "    objects = ijson.items(f, 'topics.item.subject')\n",
    "    sentences = list(objects)\n",
    "\n",
    "#Questions\n",
    "with open(datapath, 'r') as f:\n",
    "    objects2 = ijson.items(f, 'topics.item.question')\n",
    "    sentences.extend(list(objects2))\n",
    "\n",
    "    \n",
    "source = pd.DataFrame({'sentence':sentences})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#existem dados faltantes?\n",
    "source[source['sentence']==''].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removendo...\n",
    "source = source[source['sentence']!='']\n",
    "#depois da remoção\n",
    "source[source['sentence']==''].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tokenização\n",
    "source['tokenized'] = source.apply(lambda row: word_tokenize(row['sentence'].lower()), axis=1)\n",
    "\n",
    "#Faz o tagging\n",
    "source['tagged'] = source.apply(lambda row: pos_tag(row['tokenized']),axis=1)\n",
    "\n",
    "#Lematiza somente a o token, mantendo a tag original do token antes da lematização (actors, NNS) -> (actor, NNS)\n",
    "Lemmatizer = WordNetLemmatizer()\n",
    "for i in source['tagged'].index:\n",
    "    lista_aux = []\n",
    "    for tupla in source['tagged'][i]:\n",
    "        lista_aux.append( (Lemmatizer.lemmatize(tupla[0]), tupla[1]) )\n",
    "    source['tagged'][i] = lista_aux\n",
    "\n",
    "#Usa o noun-phrase extractor\n",
    "source['noun-phrases'] = source.apply(lambda row: npe.extract_cleanned(row['sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tagged</th>\n",
       "      <th>noun-phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "      <td>[bad, rap, actors, good, rap, actors, list, ?]</td>\n",
       "      <td>[(bad, JJ), (rap, NN), (actor, NNS), (good, JJ...</td>\n",
       "      <td>[[bad, rap, actor, good, rap, actor, list]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list of hispanic actors?</td>\n",
       "      <td>[list, of, hispanic, actors, ?]</td>\n",
       "      <td>[(list, NN), (of, IN), (hispanic, JJ), (actor,...</td>\n",
       "      <td>[[hispanic, actor]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LiST OF ACTORS AND ACTRESSES?</td>\n",
       "      <td>[list, of, actors, and, actresses, ?]</td>\n",
       "      <td>[(list, NN), (of, IN), (actor, NNS), (and, CC)...</td>\n",
       "      <td>[[list,  act, ors and actresses?]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are a and b list actors?</td>\n",
       "      <td>[who, are, a, and, b, list, actors, ?]</td>\n",
       "      <td>[(who, WP), (are, VBP), (a, DT), (and, CC), (b...</td>\n",
       "      <td>[[list, actor]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List of famous black actors?</td>\n",
       "      <td>[list, of, famous, black, actors, ?]</td>\n",
       "      <td>[(list, NN), (of, IN), (famous, JJ), (black, J...</td>\n",
       "      <td>[[famous, black, actor]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence  \\\n",
       "0  Bad rap actors good rap actors list?   \n",
       "1              list of hispanic actors?   \n",
       "2         LiST OF ACTORS AND ACTRESSES?   \n",
       "3          Who are a and b list actors?   \n",
       "4          List of famous black actors?   \n",
       "\n",
       "                                        tokenized  \\\n",
       "0  [bad, rap, actors, good, rap, actors, list, ?]   \n",
       "1                 [list, of, hispanic, actors, ?]   \n",
       "2           [list, of, actors, and, actresses, ?]   \n",
       "3          [who, are, a, and, b, list, actors, ?]   \n",
       "4            [list, of, famous, black, actors, ?]   \n",
       "\n",
       "                                              tagged  \\\n",
       "0  [(bad, JJ), (rap, NN), (actor, NNS), (good, JJ...   \n",
       "1  [(list, NN), (of, IN), (hispanic, JJ), (actor,...   \n",
       "2  [(list, NN), (of, IN), (actor, NNS), (and, CC)...   \n",
       "3  [(who, WP), (are, VBP), (a, DT), (and, CC), (b...   \n",
       "4  [(list, NN), (of, IN), (famous, JJ), (black, J...   \n",
       "\n",
       "                                  noun-phrases  \n",
       "0  [[bad, rap, actor, good, rap, actor, list]]  \n",
       "1                          [[hispanic, actor]]  \n",
       "2           [[list,  act, ors and actresses?]]  \n",
       "3                              [[list, actor]]  \n",
       "4                     [[famous, black, actor]]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acesso à knowledge base da NELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Monta um dataset com cada palavra de 'noun-phrases' em uma linha\n",
    "words = []\n",
    "for i,row in source.iterrows():\n",
    "    for phrase in row['noun-phrases']:\n",
    "        for word in phrase:\n",
    "            words.append(word)\n",
    "nellkb = pd.DataFrame({'word':words})\n",
    "\n",
    "#Removendo repetições\n",
    "nellkb = nellkb.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cria uma lista com cada palavra do dataset que é uma categoria da NELL\n",
    "\n",
    "#Tenta abrir o arquivo com as categorias\n",
    "try:\n",
    "    with open('categories.txt', 'r') as filehandle:\n",
    "        nell_categories = []\n",
    "        for line in filehandle:\n",
    "            # Remove '\\n', que é o último caracter de cada string\n",
    "            cat = line[:-1]\n",
    "\n",
    "            # Adiciona o item à lista\n",
    "            nell_categories.append(cat)\n",
    "        \n",
    "#Se ele não existe, cria um\n",
    "except:\n",
    "    #Procura cada palavra na knowledge base da NELL\n",
    "    nellkb['is_category'] = nellkb.apply(lambda row: z.isCategory(row['word']),axis=1)\n",
    "    nell_categories = nellkb[nellkb['is_category'] == 'yes']['word'].tolist()\n",
    "    #Salva as palavras que são categoria em um arquivo\n",
    "    with open('categories.txt', 'w') as filehandle:  \n",
    "        for cat in categories:\n",
    "            filehandle.write('%s\\n' %cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encontra quais as categorias de uma lista de palavras\n",
    "def find_category(lista):\n",
    "    cats = []\n",
    "    for item in lista:\n",
    "        if item in nell_categories:\n",
    "            cats.append(item)\n",
    "    return list(set(cats))\n",
    "\n",
    "# Encontra a tag de uma determinada palavra\n",
    "def get_tag(row, word):\n",
    "    for tupla in row:\n",
    "        if tupla[0] == word:\n",
    "            retorno = tupla[1]\n",
    "    #Se encontrou\n",
    "    try:\n",
    "        return retorno\n",
    "    #Senão\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "# Encontra o index de uma determinada palavra\n",
    "def get_index(row, word):\n",
    "    Lemmatizer = WordNetLemmatizer()\n",
    "    for item in row:\n",
    "        if word == Lemmatizer.lemmatize(item):\n",
    "            retorno = row.index(item)\n",
    "    try:\n",
    "        return retorno\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Calcula a distancia entre duas palavras\n",
    "def distancia(row, category, word):\n",
    "    cat_index = get_index(row, category)\n",
    "    word_index = get_index(row, word)\n",
    "    try:\n",
    "        return np.abs(cat_index - word_index)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=['sentence','word','nell_category',\n",
    "                                'word_tag','nell_category_tag','word_is_category',\n",
    "                                'distance_from_category','number_of_occurrences','is_category_candidate'])\n",
    "\n",
    "#Para cada linha do dataset\n",
    "for irow, row in source.iterrows():\n",
    "    #Pega uma das listas dentro da lista da coluna noun-phrase\n",
    "    for lista in row['noun-phrases']:\n",
    "        #Encontra quais são as categorias dentro da lista\n",
    "        categories = find_category(lista)\n",
    "        for category in categories:\n",
    "            #Pega a tag da categoria\n",
    "            nell_category_tag = get_tag(row['tagged'], category)\n",
    "            \n",
    "            #Percorre a lista palavra a palavra\n",
    "            for word in lista:\n",
    "                #Pega a tag da palavra\n",
    "                word_tag = get_tag(row['tagged'], word)\n",
    "                #Calcula a distancia entre a palavra e a categoria\n",
    "                distance_from_category = distancia(row['tokenized'], category, word)\n",
    "                \n",
    "                #word tem que ser diferente de category para que não haja repetição do tipo actor|actor, male|male...\n",
    "                if word != category:\n",
    "                    if word in nell_categories:\n",
    "                        word_is_category = 'yes'\n",
    "                    else:\n",
    "                        word_is_category = 'no'\n",
    "                        \n",
    "                    #Adiciona uma linha no dataset com todas as informações obtidas\n",
    "                    dataset = dataset.append({'sentence':row['sentence'],\n",
    "                                              'word':word,\n",
    "                                              'nell_category':category,\n",
    "                                              'word_tag':word_tag,\n",
    "                                              'nell_category_tag':nell_category_tag,\n",
    "                                              'word_is_category':word_is_category,\n",
    "                                              'distance_from_category':distance_from_category},\n",
    "                                              ignore_index=True)\n",
    "                    \n",
    "# Calcula o número de ocorrências                    \n",
    "for i in range(len(dataset)):\n",
    "    word = dataset['word'][i]\n",
    "    nell_category = dataset['nell_category'][i]\n",
    "    contador = 0\n",
    "    for j in range(len(dataset)):\n",
    "        if (dataset['word'][j] == word and dataset['nell_category'][j] == nell_category):\n",
    "            contador += 1\n",
    "    dataset['number_of_occurrences'][i] = contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>nell_category</th>\n",
       "      <th>word_tag</th>\n",
       "      <th>nell_category_tag</th>\n",
       "      <th>word_is_category</th>\n",
       "      <th>distance_from_category</th>\n",
       "      <th>number_of_occurrences</th>\n",
       "      <th>is_category_candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "      <td>bad</td>\n",
       "      <td>actor</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "      <td>rap</td>\n",
       "      <td>actor</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "      <td>good</td>\n",
       "      <td>actor</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "      <td>rap</td>\n",
       "      <td>actor</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad rap actors good rap actors list?</td>\n",
       "      <td>list</td>\n",
       "      <td>actor</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence  word nell_category word_tag  \\\n",
       "0  Bad rap actors good rap actors list?   bad         actor       JJ   \n",
       "1  Bad rap actors good rap actors list?   rap         actor       NN   \n",
       "2  Bad rap actors good rap actors list?  good         actor       JJ   \n",
       "3  Bad rap actors good rap actors list?   rap         actor       NN   \n",
       "4  Bad rap actors good rap actors list?  list         actor       NN   \n",
       "\n",
       "  nell_category_tag word_is_category distance_from_category  \\\n",
       "0               NNS               no                      2   \n",
       "1               NNS               no                      1   \n",
       "2               NNS               no                      1   \n",
       "3               NNS               no                      1   \n",
       "4               NNS               no                      4   \n",
       "\n",
       "  number_of_occurrences is_category_candidate  \n",
       "0                     3                   NaN  \n",
       "1                     2                   NaN  \n",
       "2                    11                   NaN  \n",
       "3                     2                   NaN  \n",
       "4                     7                   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ainda temos que checar os valores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence                    0\n",
       "word                        0\n",
       "nell_category               0\n",
       "word_tag                   48\n",
       "nell_category_tag          17\n",
       "word_is_category            0\n",
       "distance_from_category     54\n",
       "number_of_occurrences       0\n",
       "is_category_candidate     372\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
